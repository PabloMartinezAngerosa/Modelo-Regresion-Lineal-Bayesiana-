---
title: "Proyecto Inferencia Bayesiana"
author: "Vanessa Alcalde, Luciano Garrido, Pablo Martinez Angerosa"
date: "27/11/2020"
header-includes: 
- \usepackage{float}
- \floatplacement{figure}{H}
output: 
  pdf_document:
 #   fig.caption: true
    latex_engine: xelatex
bibliography: bibliografia.bib
nocite: | 
  @paper_pol
  @libro
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,tidy=TRUE, message = FALSE, warning = FALSE,fig.pos = 'h')
options(xtable.comment=FALSE)
source("Main.R")
```

# 1 Introducción

En agosto de 1973, G.C. McDonald y R.C. Schwing [1] utilizaron Regresión Ridge 
para encontrar un modelo cuyas variables regresoras, compuestas 
por variables climáticas, socioeconómicas y de polución del aire, logran 
explicar la tasa de mortalidad de 60 ciudades estadounidenses en el año 1963. Como 
mencionan los autores, si bien los métodos estadísticos no necesariamente 
implican un relación de causa y efecto, bajo el supuesto de que esta relación 
existe, estos métodos proveen una herramienta para entender las contribuciones 
relativas a una variable de estudio. 

En esta investigación utilizamos el método de Bayes empírico para obtener las 
distribuciones de los coeficientes que explican la tasa de mortalidad sobre la 
misma base de datos que utilizaron G.C. McDonald y R.C. Schwing [1]. 
Para esto en una primera instancia se ajusta un modelo de regresión lineal 
múltiple, donde en el proceso de construcción se 
eliminaron algunas variables explicativas que no resultaron significativas. Al 
mismo tiempo los coeficientes $\beta_i$ que se obtienen del modelo lineal 
construido a partir de la muestra dada de datos pasan a ser los ejes 
principales de información a priori de los parámetros dándole al análisis el 
enfoque empírico bayesiano. Junto a esto se realiza un modelo de regresión 
lineal bayesiano y se comparan los resultados.

# 2 Datos

Los datos corresponden a 60 ciudades de Estados Unidos en el año 1963 y fueron 
obtenidos de la base de datos correspondientes al artículo original de G.C. 
McDonald and R.C. Schwing, "Instabilities of Regression Estimates Relating Air 
Pollution to Mortality" [1]. Cuenta con 16 variables cuantitativas agrupadas en 
las categorías climática, socioeconómica y de polución del aire. La Tabla 1 
muestra la descripción de las variables en la base de datos.

\renewcommand{\tablename}{Tabla}

```{r, results='asis'}

MostrarTablaDescriptiva()

```

Las variables etiquetadas como HC, NOX y SO pertenecen a la categoría de 
polución del aire, como se muestra en la Figura 1, HC y NOX presentan una 
correlación elevada de 0.98 y por lo tanto la información que estas variables 
adhieren al modelo es simplemente de incertidumbre, por lo cual optamos por 
excluir la variable explicativa NOX.

Las variables PREC, JANT, JULT y HUMID pertenecen a la categoría de climáticas.

Las variables MORT, OVR65, POPN, EDUC, HOUS, DENS, NONW, WWDRK y POOR 
pertenecen a la categoría de variables socioeconómicas. Estas variables son 
importantes para poder medir las diferencias en los estados de salud de las 
distintas comunidades. La variable explicada MORT representa la tasa de 
mortalidad cada 100,000 habitantes. Existen correlaciones de 0.7 entre EDUC y 
WWDRK y entre NONW y POOR. Análisis de multicolinealidad realizados 
posteriormente en la búsqueda del ajuste del modelo lineal primario no dieron 
argumentos suficientes para excluir alguna de estas variables.


\renewcommand{\figurename}{Figura}


```{r, fig.cap ="Gráfico de dispersión de HC contra NOX.",fig.pos="H", fig.height = 3, fig.width = 3}

MostrarGraficoCorrelacion()

```

En la Tabla 2 se muestra la media, el mínimo y el máximo para las 16 variables 
cuantitativas.

```{r, results='asis'}

MostrarTablaResumen()

```

\newpage

# 3 Métodos

Los tres modelos utilizados en esta investigación incluyen regresión lineal 
múltiple, modelo bayesiano y modelo bayesiano empírico. El proceso consistió 
primero en obtener un modelo de regresión lineal múltiple que cumpla con los supuestos 
teóricos y que esté compuesto por un conjunto de variables significativas. 
Posteriormente utilizamos la información obtenida de las estimaciones puntuales 
de los $\beta_{i}$ y el $\sigma^{2}$ como información a priori para realizar un modelo bayesiano 
empírico con las mismas variables resultantes del modelo de regresión. Para 
finalizar realizamos un modelo bayesiano utilizando como distribuciones a priori 
las default presentes en el paquete *rstanarm* de *R* para que este realice un ajuste por escala de 
las posterioris y comparamos el desempeño de todos los modelos.

## 3.1 Metodología

Un modelo de regresión lineal múltiple es un modelo lineal en los parámetros 
en el cual la variable de respuesta, $Y$, es determinada por un conjunto de 
variables independientes, las variables explicativas. Se busca el hiperplano 
que mejor ajuste a los datos. 

\begin{equation}
\tag{1}
\label{mod_lineal}
Y_{i} = \boldsymbol{\beta}^{T}  \boldsymbol{x}_{i} + \varepsilon_{i}
\end{equation}

Asumiendo las hipótesis de Gauss-Markov los $\varepsilon_{i} \sim N(0,\sigma^{2})$ 
y son incorrelacionados. Los $\beta_{i}$ y las $\boldsymbol{x}_i$ son considerados 
constantes y por ende la variable explicada de la Ecuación (\ref{mod_lineal}) 
distribuye $y_{i} \sim normal(\beta^{T} x_{i}, \sigma^{2})$.
Las estimaciones puntuales de los $\beta_{i}$ que minimizan el error cuadrático 
medio del modelo se obtienen por el método de mínimos cuadrados ordinarios (MCO).

Por otro lado, los modelos bayesianos son capaces de sintetizar la información 
de la muestra y una creencia a priori, no muestral, utilizando el Teorema de Bayes. La 
creencia a priori de los parámetros que se quieren estimar se expresan a través 
de una distribución de probabilidad, llamada distribución a priori. Los 
parámetros a estimar, a diferencia del enfoque clásico, ya no son una estimación 
puntual sino que tienen un comportamiento de distribución dentro de una medida 
de probabilidad.

En la Ecuación (\ref{mod_lineal}) dentro de un enfoque bayesiano, los 
$\beta_{i}$ y $\sigma^{2}$ son variables aleatorias.

La distribución conjunta resultante de la Ecuación (\ref{mod_lineal}) es

\begin{equation}
\tag{2}
\label{conjunta}
\begin{array}{l}
p\left(y_{1}, \ldots, y_{n} \mid x_{1}, \ldots x_{n}, \beta, \sigma^{2}\right) \\
=\prod_{i=1}^{n} p\left(y_{i} \mid \boldsymbol{x}_{i}, \boldsymbol{\beta}, \sigma^{2}\right) \\
=\left(2 \pi \sigma^{2}\right)^{-n / 2} \exp \left\{-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(y_{i}-\boldsymbol{\beta}^{T} \boldsymbol{x}_{i}\right)^{2}\right\}
\end{array}
\end{equation}

Si el vector de $\boldsymbol{\beta} \sim Normal \ multivariada(\beta_{0}, \Sigma_{0})$ 
obtenemos que la posteriori normal conjugada es


\begin{equation}
\tag{3}
\label{post}
\begin{array}{l}
p\left(\boldsymbol{\beta} \mid \boldsymbol{y}, \mathbf{X}, \sigma^{2}\right) \\
\propto p\left(\boldsymbol{y} \mid \mathbf{X}, \boldsymbol{\beta}, \sigma^{2}\right) \times p(\boldsymbol{\beta}) \\
\propto \exp \left\{-\frac{1}{2}\left(-2 \boldsymbol{\beta}^{T} \mathbf{X}^{T} \boldsymbol{y} / \sigma^{2}+\boldsymbol{\beta}^{T} \mathbf{X}^{T} \mathbf{X} \boldsymbol{\beta} / \sigma^{2}\right)-\frac{1}{2}\left(-2 \boldsymbol{\beta}^{T} \Sigma_{0}^{-1} \boldsymbol{\beta}_{0}+\boldsymbol{\beta}^{T} \Sigma_{0}^{-1} \boldsymbol{\beta}\right)\right\} \\
=\exp \left\{\boldsymbol{\beta}^{T}\left(\Sigma_{0}^{-1} \boldsymbol{\beta}_{0}+\mathbf{X}^{T} \boldsymbol{y} / \sigma^{2}\right)-\frac{1}{2} \boldsymbol{\beta}^{T}\left(\Sigma_{0}^{-1}+\mathbf{X}^{T} \mathbf{X} / \sigma^{2}\right) \boldsymbol{\beta}\right\}
\end{array}
\end{equation}

Un desafio importante de la estadística bayesiana es definir la información 
necesaria para construir la distribución a priori. Incluso algunas veces ni 
siquiera existe información previa o precisa que se pueda considerar como una 
creencia de los parámetros. 

Un posible enfoque a esta problemática es la utilización de un modelo bayesiano 
empírico y utilizar los $\beta$ obtenidos por mínimos cuadrados para 
centrar las distribuciones a priori en base a estos parámetros puntuales 
estimados.

Los métodos empíricos de Bayes son procedimientos de inferencia estadística en 
los cuales la creencia a priori se construye a partir de los datos. Si bien, 
Kass y Wasserman (1995) en [2] sugieren que esta distribución no puede 
considerarse una previa real, la cantidad de información de $y$ que se utiliza no 
es de un margen considerable.

Otro posible problema de este enfoque es que no se conoce las distribuciones de 
los $\beta_{i}$, pero en esta investigación consideramos que son normales, 
centradas en los $\beta_{i}$ estimados por MCO y con desviaciones típicas basadas en 
los desvíos de estos parámetros.

Para tener una medida de comparación entre distintos modelos se utilizó el 
criterio de predicción RMSE descrito en la Ecuación (\ref{RMSE}) donde $y_i$ 
representa las predicciones y $f_i$ los valores reales. El mejor desempeño 
se asocia a un menor RMSE.

\begin{equation}
\tag{4}
\label{RMSE}
R M S E=\sqrt{\frac{1}{N} \sum_{i=1}^{N}\left(y_{i}-f_{i}\right)^{2}}
\end{equation}

Para obtener las simulaciones de las cadenas se utilizó el paquete *stanarm* de 
*R*, el cual genera 4 cadenas con 2000 simulaciones cada una para obtener 
simulaciones Markov MonteCarlo (MCMC) de la posteriori. Las primeras 1000 cadenas 
son desechadas para evitar la dependencia con los valores iniciales y que se estabilice la cadena. Dos 
indicadores que se utilizan para monitorear un indicio de convergencia son el 
$\hat{R}$ y el número de muestras efectivas, $\hat{n}_{eff}$. Las medidas 
$\hat{R} <1.1$ y $\hat{n}_{eff} > 5m$, entendiendo $m$ como el número de cadenas, 
se consideran un indicio de convergencia.

Las prioris por defecto en *stanarm* fueron diseñadas para ser levemente 
informativas. Según la documentación en muchos casos, sino en la mayoría, los 
valores por defecto van a obtener un buen desempeño, aunque no siempre suceda.
La forma en la que este paquete funciona es a través del ajuste de la escalde las 
prioris. La priori auxiliar, el desvío estándar, por defecto tiene una configuración 
de $exponencial(1)$. La priori para los coeficientes son normales centradas en $0$ 
y con una escala (desviación estádar) de $2.5$.

## 3.2 Los modelos

A continuación en la Ecuación (\ref{modelo_final}) se muestra el modelo 
resultante por modelos lineales. Todas las variables de la base original 
fueron analizadas en modelos preliminares pero muchas resultaron no significativas por 
lo que no se incluyen en el modelo final. Las variables PREC, NONW y SO 
resultaron significativas a un 0.1% y JANT, JULT y EDUC al 5%. Se puede ver en 
el modelo final que quedan variables de las tres categorías principales en las 
que fueron organizadas en la base. 

Este modelo es significativo globalmente al 95% de confianza y logra una variablidad explicada de 
la $y_i$ expresada mediante el $R^{2}$ de un 0.8076 y un $R^{2}$ ajustado de 
un 0.7836 (el cual penaliza por la cantidad de regresores), logrando un 
buen despeño.

Se decidió sacar de la base de datos cinco observaciones que resultaron 
influyentes o atípicas luego de los análisis correspondientes y esto se 
corroboró dado que al excluirlas de la base y volver a ajustar el modelo se 
apreciaba un cambio sustancial en el $R^{2}$ y el valor de los $\beta_{i}$ 
estimados.

\begin{equation}
\tag{5}
\label{modelo_final}
MORT_i = \beta_0 + \beta_{1}PREC_{i} + \beta_{2}JANT_{i} + \beta_{3}JULT_{i} + \beta_{4}EDUC_{i} + \beta_{5}NONW_{i} + \beta_{6}SO_{i} + \varepsilon_{i}
\end{equation}


Donde $\varepsilon_{i} \sim N(0, \sigma^{2})$, $Cov(\varepsilon_{i},\varepsilon_{j})=0 \ \forall \ i \neq j$.


El mismo modelo de la Ecuación (\ref{modelo_final}) se utiliza para el enfoque bayesiano y el bayesiano empírico. En la Tabla 3 se muestran el resumen de las medias y las desviaciones típicas de las distribuciones a priori normales utilizadas para los parámetros $\beta_i$ y $\sigma^{2}$ del modelo bayesiano empírico. Estos parámetros de las distribuciones a priori están basados en los resultados estimados por MCO del modelo de regresión lineal.

```{r, results='asis'}

MostrarTablaPreviaBayesianoEmpirico()

```


# 4 Resultados

En esta sección mostramos los resultados obtenidos para ambos modelos 
bayesianos, hacemos la comprobación de ambos y posteriormente comparamos el 
despeño de los tres modelos ajustados.

En la Tabla 4 se muestran los resultados obtenidos de los indicadores de 
convergencia, $\hat{R}$ y $\hat{n}_{eff}$ para ambos modelos bayesianos. Como se 
puede observar los indicadores sugieren que no hubo problemas de convergencia 
para ambos modelos.

```{r, results='asis'}

MostrarTablaConvergenciaBayesiano()

```

La Tabla 5 muestra los intervalos de credibilidad de las distribuciones 
posteriori de los parámetros para ambos modelos en un 95%. Los números reflejan 
que no hay grandes diferencias y todos los intervalos se intersectan en su mayoría.


```{r, results='asis'}

MostrarTablaIntervalosCredibilidadBayesianos()

```

En la Figura 2 se muestran las distribuciones de los estadísticos para las 
distintas simulaciones en ambos modelos bayesianos. Se puede ver que ambos tienen un buen 
desempeño en estadísticos con distintos criterios como la mediana, el rango 
intercuartílico y el máximo. El desempeño entre los dos modelos es muy similar.

```{r,fig.cap ="Gráfico comparativo de estimadores, en la izquierda se muestran la mediana, el rango intercuartílico y el máximo para el modelo de Bayes y en la derecha los mismos estimadores para el modelo de Bayes empírico.",fig.pos="H"}

MostrarGraficosEstadisticos()

```

La Figura 3 muestra las distribuciones simuladas de la distribución
predictiva posteriori para ambos modelos, estas son contrastadas con la 
distribución empírica de la variable explicada, la tasa de mortalidad. Se puede 
apreciar que existe una mayor concentración de las simulaciones para el modelo 
bayesiano empírico, pero igualmente ambos modelos muestran buenos resultados.

```{r,fig.cap ="Gráfico comparativo de las predictivas posteriori, en la imagen superior se muestra el modelo de Bayes y en la inferior el modelo de Bayes empírico.",fig.pos="H", fig.height = 3, fig.width = 3}

MostrarGraficosPosterioriPredictiva()

```

En la Tabla 6 utilizamos el RMSE como medida predictiva para establecer una medida 
de comparación entre los modelos. Se puede observar que entre los modelos bayesianos 
hay una diferencia muy pequeña de error en favor del modelo bayesiano empírico 
pero podemos concluir que ambos logran un mismo desempeño predictivo. Sin embargo, 
comparando ambos con el resultado obtenido por modelos lineales se aprecia una 
diferencia considerable en la exactitud de predicción en favor de los modelos 
bayesianos.

```{r, results='asis'}

MostrarTablaRMSE()

```

Desde otra perspectiva, en la Tabla 7 se observa como las estimaciones para todos 
los parámetros, tanto las puntuales de modelos lineales como las medias en las que 
se centran las distribuciones obtenidas de las posterioris por modelos bayesianos 
y sus desvíos correspondientes, se encuentran en entornos cercanos sin notarse 
diferencias considerables en las estimaciones propuestas por cada modelo. Observando 
los desvíos correspondientes se ve una mayor concentración en las medias en el 
modelo bayesiano empírico.


```{r, results='asis'}

MostrarTablaResumenPosteriori()

```


# 5 Discusión y conclusiones

En esta investigación se utilizaron modelos estadísticos de regresión lineal 
múltiple, bayesianos y bayesianos empírico con una misma base de datos. Los tres 
modelos estimados muestran consistencia entre sí, ya que tanto los parámetros puntuales 
para los $\beta_{i}$ obtenidos por modelos lineales y las medias de las distribuciones 
de los parámetros a posteriori por modelos bayesianos, se mueven en intervalos muy similares. 

Aunque el modelo bayesiano fue obtenido mediante una búsqueda de las distribuciones posterioris, mediante ajuste por escala,  
sin ninguna información previa de la muestra, este logra obtener una similitud 
muy grande con las posterioris encontradas por el modelo bayesiano empírico, cuya 
información a priori estaba centrada en información de la muestra, particularmente 
de los parámetros obtenidos por MCO. Al mismo tiempo, el modelo bayesiano logra una similitud con el 
modelo lineal. De igual manera las distribuciones obtenidas por el modelo bayesiano 
empírico no se alejan tanto de la información a priori establecida. Esto nos da a 
interpretar que hay una validación de las variables y las estimaciones obtenidas.

En cuanto a un enfoque de selección de uno de los tres modelos, el modelo bayesiano 
empírico es el que logra un mejor desempeño en los distintos casos evaluados. Desde 
una óptica de predicción el modelo empírico bayesiano logra una pequeña diferencia 
a favor sobre el modelo bayesiano, y una diferencia considerable sobre el modelo lineal.
En cuanto a lo observado, el modelo bayesiano empírico demuestra una mayor 
concentración de las simulaciones de la distribución predictiva con respecto 
a la variable explicada en comparativa con el modelo bayesiano.

A futuro, sería interesante comparar los resultados de esta investigación para datos actualizados 
con las mismas variables y comprobar si se siguen obteniendo los mismos resultados de desempeño 
y el mismo conjunto de variables significativas para los modelos propuestos.


# Referencias